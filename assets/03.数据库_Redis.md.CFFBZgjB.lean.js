import{_ as i,c as e,a2 as r,o as p}from"./chunks/framework.6NRZc4eo.js";const h=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"03.数据库/Redis.md","filePath":"03.数据库/Redis.md","lastUpdated":null}'),a={name:"03.数据库/Redis.md"};function s(t,l,o,d,n,c){return p(),e("div",null,l[0]||(l[0]=[r('<h2 id="redis为什么这么快" tabindex="-1">Redis为什么这么快 <a class="header-anchor" href="#redis为什么这么快" aria-label="Permalink to &quot;Redis为什么这么快&quot;">​</a></h2><ol><li><p>数据存储在内存中：Redis的数据存储在内存中，而内存的读写速度远远快于硬盘。</p></li><li><p>单线程处理请求：Redis是单线程的，因此可以避免线程切换和锁竞争等问题，提高了CPU的利用率和性能。</p></li><li><p>高效的数据结构： Redis 提供了多种高效的数据结构，如哈希表、有序集合等，这些数据结构能够快速地进行插入、删除、查找和排序等操作。</p></li><li><p>异步IO： Redis 使用异步 I/O 技术，可以在等待客户端输入或输出时继续处理其他请求，从而提高了系统的吞吐量。</p></li><li><p>高效的持久化机制： Redis 提供了多种持久化机制，如 RDB、AOF 和混合持久化机制，这些机制运行都非常高效，可以在不影响性能的情况下保证数据的安全。</p></li></ol><h3 id="_1、redis实现分布式锁-redisson" tabindex="-1">1、redis实现分布式锁(redisson) <a class="header-anchor" href="#_1、redis实现分布式锁-redisson" aria-label="Permalink to &quot;1、redis实现分布式锁(redisson)&quot;">​</a></h3><p><a href="https://tencentcloud.csdn.net/676397acf3b8a55e4e98e05d.html" target="_blank" rel="noreferrer">https://tencentcloud.csdn.net/676397acf3b8a55e4e98e05d.html</a></p><p><a href="https://cloud.tencent.com/developer/article/2308353" target="_blank" rel="noreferrer">https://cloud.tencent.com/developer/article/2308353</a></p><p>使用setnx命令加锁，导致如下问题</p><ul><li>未释放锁，导致死锁；**解决方案：**设置过期时间。</li><li>设置的过期时间小于业务执行时间，导致锁过期；**解决方案：**客户端开启守护线程（watch dog）为锁续期。</li><li>解锁时，未检查锁的归属，释放了别人的锁；**解决方案：**设置锁时，key加入唯一标识，Lua脚本，先判断锁是否属于自己，再Del释放锁。</li></ul><p><strong>Redisson解决了锁的可重入和续期问题。</strong></p><p>Redisson在redis单机下可以解决以上分布式问题，但正式环境下，redis主从集群+哨兵模式下，如果部分节点加锁失败，主从未同步成功（主从异步同步），会导致加锁失败。</p><p>解决方案：RedLock实现高可靠的分布式锁。</p><p>出现节点崩溃重启，会出现多个客户端持有锁</p><p>解决方案：节点崩溃后，不立即重启，而是等待一段时间再重启，等待的时间大于锁的有效时间。通过人为补偿的方式，降低不一致发生的概率。</p><p>RedLock缺点：</p><ul><li><strong>性能问题</strong>：RedLock 要等待大多数节点返回之后，才能加锁成功，而这个过程中可能会因为网络问题，或节点超时的问题，影响加锁的性能。</li><li><strong>并发安全性问题</strong>：当客户端加锁时，如果遇到 GC 可能会导致加锁失效，但 GC 后误认为加锁成功的安全事故</li></ul><p><strong>RedLock已经逐渐被废弃？</strong></p><p><strong>redis 红锁被抛弃后用什么代替</strong> ？</p><p><a href="https://blog.51cto.com/u_12187/12246223" target="_blank" rel="noreferrer">https://blog.51cto.com/u_12187/12246223</a></p><p>Redisson源码分析</p><p>watch dog：</p><p>自旋阻塞、唤醒机制保证高性能：</p><p>Netty中TimerTask，时间轮：</p><p>方法嵌套，递归，中间件里很常用的一种定时任务实现：</p><p>观察者模式（发布-订阅）</p><h3 id="_2、redis用于哪些场景" tabindex="-1">2、redis用于哪些场景？ <a class="header-anchor" href="#_2、redis用于哪些场景" aria-label="Permalink to &quot;2、redis用于哪些场景？&quot;">​</a></h3><ul><li><p>String</p><ul><li>登录鉴权，验证码、token失效</li><li>防刷，设置过期时间</li></ul></li><li><p>list</p><ul><li>消息队列，电商秒杀、集中约课等高并发写场景下</li><li>浏览器历史记录。通过list实现栈功能，进而实现浏览器历史记录场景；<code>lpush</code>、<code>lpop</code></li></ul></li><li><p>Set数据类型，天然去重的集合，提供了求交集、并集等一系列方法，适合共同或单方面好友、粉丝、爱好之类的业务</p><ul><li>抽奖设计</li><li>点赞收藏设计，粉丝关注</li><li>社交系统中好友关系设计</li><li>用户签到</li></ul></li><li><p>Zset</p><p>具备高性能的原因有二</p><ol><li>用空间换时间的预计算思想</li><li>优秀的底层数据结构，通过skiplist（跳表）+ dict（哈希表）+ listpack实现的</li></ol><ul><li>排行榜</li></ul></li><li><p>bitMaps（位图）</p><p>用户签到虽然Set也可以实现，但用户量庞大的情况下，会极大占用内存空间，使用bitmap，通过bit位来进行状态存储。</p></li><li><p>HyperLogLog</p><p>提供不精确的去重方案，标准误差0.8%，但仅仅占用12K的内存空间</p><p>网站UV（Unique Visitor）统计；与PV（page Visitor）不同的是需要去重，虽然Set也可以，但是极消耗内存。</p></li><li><p>地理空间索引GEO</p><p>用于存储地理位置信息，并支持基于地理位置的查询和计算</p></li><li><p>计数器：帖子点赞、收藏、电商的库存扣减</p></li><li><p>分布式锁。setnx</p></li></ul><h3 id="_3、-redis缓存穿透、缓存击穿、缓存雪崩" tabindex="-1">3、 redis缓存穿透、缓存击穿、缓存雪崩 <a class="header-anchor" href="#_3、-redis缓存穿透、缓存击穿、缓存雪崩" aria-label="Permalink to &quot;3、 redis缓存穿透、缓存击穿、缓存雪崩&quot;">​</a></h3><ol><li><p>缓存穿透</p><p>透意味着没有命中redis，直接打到数据库上，比如不存在的id值等。</p><ul><li>布隆过滤器。核心思想：当某个值存在时，这个值不一定存在；当某个值不存在时，那么这个值一定不存在。</li></ul></li><li><p>缓存击穿</p><p>击意味着命中了redis，但redis同时失效，导致直接打到数据库上。</p><ul><li>设置不同的过期时间，相对分散一些</li><li>添加降级限流操作，给出友好提示</li></ul></li><li><p>缓存雪崩</p><p>原因：redis的不可用，和缓存击穿类似，导致数据全部打到mysql导致的。</p><ul><li>保证redis高可用，搭建多节点cluster集群，或者搭建简单的哨兵集群</li><li>设置限流降级功能，请求先达到web服务器，然后再进入redis，对多余的请求进行一个平滑的降级，比如给一个友好的提示页面</li><li>使用mq。将请求加入到mq队列中，然后异步告知用户前面还有多少人在排队，让用户等待</li><li>上线前对redis进行压测，对redis进行数据备份，合理的设置JVM服务的个数，mysql的架构等</li><li>redis内部进行优化，如解决bigkey问题，批量的操作数据，合理选择数据类型</li></ul></li></ol><h3 id="_4、redis多级缓存" tabindex="-1">4、redis多级缓存 <a class="header-anchor" href="#_4、redis多级缓存" aria-label="Permalink to &quot;4、redis多级缓存&quot;">​</a></h3><ul><li><p>使用本地缓存做一级缓存Ecache、guava、caffeine。使用redis做二级远程缓存。</p></li><li><p>对于一些变更频率较高的数据，采用集中式缓存，这样能够确保所有节点在数据变化后实时更新，从而保证数据的一致性。</p></li><li><p>对于一些极少变更的数据（如系统配置项）或者是一些对短期一致性要求不高的数据（如用户昵称、签名等）采用本地缓存，显著降低对远程集中式缓存的网络IO次数，提高系统性能。</p></li></ul><h3 id="_5、如何保证mysql和redis中的数据一致性" tabindex="-1">5、如何保证Mysql和redis中的数据一致性？ <a class="header-anchor" href="#_5、如何保证mysql和redis中的数据一致性" aria-label="Permalink to &quot;5、如何保证Mysql和redis中的数据一致性？&quot;">​</a></h3><ol><li><p>数据不一致原因</p><p>分布式场景中，并发带来的问题，网络抖动带来的问题，分布式事务不一致问题等。</p></li><li><p>数据不一致解决方案：</p><ul><li>延迟双删（不推荐）。不能完全解决，只能减少这种数据不一致概率的事件发生，适用于读多写少的场景，如商品首页等。</li><li>消息队列。</li><li>分布式锁。</li><li>canal同步。原理类似mysql的主从复制原理，伪装成一个从节点，监听mysql的binlog日志，然后将执行的mysql的操作。</li></ul></li></ol><h3 id="_6、redis的key淘汰策略-8种-内存满了怎么办" tabindex="-1">6、redis的key淘汰策略（8种）|内存满了怎么办？ <a class="header-anchor" href="#_6、redis的key淘汰策略-8种-内存满了怎么办" aria-label="Permalink to &quot;6、redis的key淘汰策略（8种）|内存满了怎么办？&quot;">​</a></h3><p><strong>LRU 算法和 LFU算法</strong></p><p>可能同学们会觉得LRU和LFU两种算法容易混淆，我在这⾥解释⼀下。</p><p>如果有⼀条许久不曾被访问的冷数据，偶然间被访问了⼀次，如果按照LRU算法的规则，这条数据就会 被定义为热数据，短期内不会被淘汰。</p><p>但按照LFU算法的规则，这条数据可能仍然是最近⼀段时间内被访问频率最低的，还是会被淘汰掉的。</p><p><strong>LRU关注于“最近是否被访问”，LFU关注于“最近的访问频率如何”，相对⽽⾔，后者的实现⽅式更加合 理⼀些。</strong></p><ol><li><p>noeviction（默认）：到达maxmemory值时，不淘汰任何数据。当内存超限时，写操作会返回错误，而读操作则正常执行。这种策略适合数据量不大，作为DB存储使用的情况。</p></li><li><p>volatile-lru：通过近似LRU算法，淘汰key，key的范围是设置了过期时间的key，可以区分冷热数据。</p><p>标准的LRU算法是双向链表+hash表，双向链表的插入和删除操作的时间复杂度都是O(1)，hash表的查找的时间复杂度是O(1)，两者结合，堪称完美。</p><p>采用近似LRU算法的原因：</p><ol><li>redis内部只实现了hash表，需要额外实现双线链表，内存消耗的代价不可接受。</li><li>每个redis请求，LRU的双向链表需要进行同步操作，这种实现方式对性能影响不小。</li></ol><p>redis近似LRU算法，虽然没有付出大的内存和性能代价，但牺牲了一些内存淘汰的准确率。</p><p>具体实现：</p><ol><li>采用LRU时钟值的方式，记录数据每次被访问的时间。</li><li>淘汰池概念</li><li>批次数据的数量是由参数maxmemory-samples参数设置的，该参数值越大，则淘汰准确率越高，但会增加CPU消耗</li><li>从待淘汰数据池中，淘汰掉空闲时间最⼤的那条数据，同时会根据Redis中的惰性删除配置，来决 定在Redis字典中执⾏同步删除还是异步删除。</li></ol></li><li><p>volatile-lfu：通过LFU算法，淘汰key，key的范围是设置了过期时间的key，能够区分冷热数据。</p></li><li><p>volatile-ttl：淘汰redis中剩余时间最短的key，key的范围是设置了过期时间的key，适合按时间区分冷热数据。</p></li><li><p>volatile-random：以随机的方式淘汰redis中的key，key的范围是设置了过期时间的key。</p></li><li><p>allkeys-lru：key的范围是所有的key</p></li><li><p>allkeys-lfu：key的范围是所有的key</p></li><li><p>allkeys-random：key的范围是所有的key</p></li></ol><p><strong>注：</strong></p><p>LRU：least recently used，最近最少使用，用当前时间减去上一次使用时间，值越大越先被删除。</p><p>LFU：least Frequently used，最不常用，统计每个key的访问频率，值越小越先被删除。</p><p>ttl：time to live，健值对的过期时间</p><p>volatile ：/ˈvɑːlətl/不稳定的</p><blockquote><p>淘汰策略的使用建议</p></blockquote><ol><li>优先使用allkeys-lru策略，充分利用LRU算法的优势，把最近最常访问的数据留在缓存中。如果有明显的冷热数据区分，建议使用。</li><li>如果业务中数据访问频率差别，没有冷热数据区分，建议使用allkeys-random，随机选择淘汰。</li><li>如果业务中有置顶需求，可以使用volatile-lru策略，同时置顶数据不设置过期时间，这些数据就一直不被删除，会淘汰其他设置过期时间的数据。</li><li>如果业务中有短时高频访问的数据，可以使用allkeys-lfu或volatile-lfu策略。</li></ol><h3 id="主从架构数据同步一致性原理" tabindex="-1">主从架构数据同步一致性原理 <a class="header-anchor" href="#主从架构数据同步一致性原理" aria-label="Permalink to &quot;主从架构数据同步一致性原理&quot;">​</a></h3><p><a href="https://xie.infoq.cn/article/85b537627355b21b02760f306" target="_blank" rel="noreferrer">https://xie.infoq.cn/article/85b537627355b21b02760f306</a></p><h3 id="redis-基本数据类型-采用的底层数据结构" tabindex="-1">redis 基本数据类型 采用的底层数据结构 <a class="header-anchor" href="#redis-基本数据类型-采用的底层数据结构" aria-label="Permalink to &quot;redis 基本数据类型 采用的底层数据结构&quot;">​</a></h3>',48)]))}const k=i(a,[["render",s]]);export{h as __pageData,k as default};
