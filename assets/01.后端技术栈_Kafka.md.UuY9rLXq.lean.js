import{_ as e,c as l,a0 as r,o as i}from"./chunks/framework.DNN_1AUP.js";const u=JSON.parse('{"title":"windows启动","description":"","frontmatter":{},"headers":[],"relativePath":"01.后端技术栈/Kafka.md","filePath":"01.后端技术栈/Kafka.md"}'),o={name:"01.后端技术栈/Kafka.md"};function t(n,a,s,h,d,p){return i(),l("div",null,a[0]||(a[0]=[r('<h3 id="简介" tabindex="-1">简介 <a class="header-anchor" href="#简介" aria-label="Permalink to &quot;简介&quot;">​</a></h3><p>Kafka是分布式<strong>事件流</strong>平台，用于<strong>高性能数据管道</strong>、流分析、数据集成和关键任务应用程序</p><h3 id="_3个关键功能" tabindex="-1">3个关键功能 <a class="header-anchor" href="#_3个关键功能" aria-label="Permalink to &quot;3个关键功能&quot;">​</a></h3><ol><li>发布（写入）、订阅（读取）事件流。</li><li>持久化。持久可靠的<strong>存储</strong>事件流</li><li>在事件发生或回顾性地<strong>处理</strong>事件流</li></ol><h3 id="使用案例" tabindex="-1">使用案例 <a class="header-anchor" href="#使用案例" aria-label="Permalink to &quot;使用案例&quot;">​</a></h3><ul><li>消息传递</li><li>网站活动跟踪</li><li>指标</li><li>日志聚合</li><li>流处理</li><li>事件溯源</li><li>提交日志</li></ul><h4 id="应用场景" tabindex="-1">应用场景 <a class="header-anchor" href="#应用场景" aria-label="Permalink to &quot;应用场景&quot;">​</a></h4><ul><li>缓存/削峰</li><li>异步通讯</li><li>解耦</li></ul><h4 id="消息队列模式" tabindex="-1">消息队列模式 <a class="header-anchor" href="#消息队列模式" aria-label="Permalink to &quot;消息队列模式&quot;">​</a></h4><ul><li>点对点</li><li>发布/订阅</li></ul><h4 id="分区的策略" tabindex="-1">分区的策略 <a class="header-anchor" href="#分区的策略" aria-label="Permalink to &quot;分区的策略&quot;">​</a></h4><ul><li>指定分区</li><li>设置key，通过key的hash值取余</li><li>既不指定分区，也不设置key。通过黏性分区器进行分区，尽量先一个分区，等batch.size满后，换另一分区</li><li>自定义分区器，实现 Partitioner 接口，并重写方法。 ProducerConfig.PARTITIONER_CLASS_CONFIG 参数指定全路径自定义类</li></ul><h4 id="kafka中key的作用" tabindex="-1">Kafka中key的作用 <a class="header-anchor" href="#kafka中key的作用" aria-label="Permalink to &quot;Kafka中key的作用&quot;">​</a></h4><ul><li>决定分区，根据key的hash值对partition的值取余，判断哪个分区</li><li>负载均衡和高伸缩性</li><li>副本选择，指定key可以帮助在多个副本中选择合适的Leader，确保数据的高可用性和容错性。</li></ul><h4 id="压缩算法比对" tabindex="-1">压缩算法比对 <a class="header-anchor" href="#压缩算法比对" aria-label="Permalink to &quot;压缩算法比对&quot;">​</a></h4><p>但对于 Kafka 而言， 即在</p><ul><li><p>吞吐量方面：LZ4 &gt; Snappy &gt; zstd 和 GZIP；</p></li><li><p>压缩比方面，zstd &gt; LZ4 &gt; GZIP &gt; Snappy 。如果网络不好且 CPU 资源够的话,建议使用 zstd 压缩</p></li></ul><p>具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少，这是合理的，毕竟 zstd 就是要提供超高的压缩比；</p><p>在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU</p><h3 id="生产经验" tabindex="-1">生产经验 <a class="header-anchor" href="#生产经验" aria-label="Permalink to &quot;生产经验&quot;">​</a></h3><h4 id="生产者如何提高吞吐量" tabindex="-1">生产者如何提高吞吐量 <a class="header-anchor" href="#生产者如何提高吞吐量" aria-label="Permalink to &quot;生产者如何提高吞吐量&quot;">​</a></h4><ul><li>batch.size：批次大小，默认16k</li><li>linger.ms：等待时间，修改为5-100ms</li><li>compression.type：压缩snappy</li><li>RecordAccumulator：缓冲区大小，修改为64m</li></ul><h4 id="数据可靠性" tabindex="-1">数据可靠性 <a class="header-anchor" href="#数据可靠性" aria-label="Permalink to &quot;数据可靠性&quot;">​</a></h4><ul><li><p>ack应答级别</p><ul><li>0；不需要等数据落盘应答</li><li>1；Leader收到数据后应答</li><li>-1/all；Leader和ISR队列里面的所有节点收齐数据后应答</li></ul></li></ul><p><strong>思考：Leader收到数据，所有Follower都开始同步数据， 但有一个Follower，因为某种故障，迟迟不能与Leader进行 同步，那这个问题怎么解决呢？</strong></p><p>Leader维护了一个动态的in-sync replica set（ISR），意为和 Leader保持同步的Follower+Leader集合(leader：0，isr:0,1,2)。 如果Follower长时间未向Leader发送通信请求或同步数据，则 该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参 数设定，默认30s。例如2超时，(leader:0, isr:0,1)。 这样就不用等长期联系不上或者已经故障的节点。</p><p><strong>数据完全可靠条件 = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</strong></p><h4 id="数据去重" tabindex="-1">数据去重 <a class="header-anchor" href="#数据去重" aria-label="Permalink to &quot;数据去重&quot;">​</a></h4><ul><li><p>至少一次（At Least Once）= ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2</p></li><li><p>最多一次（At Most Once）= ACK级别设置为0</p></li><li><p>总结：</p><ul><li><p>At Least Once可以保证数据不丢失，但是不能保证数据不重复；</p></li><li><p>At Most Once可以保证数据不重复，但是不能保证数据不丢失。</p></li><li><p>精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。 Kafka 0.11版本以后，引入了一项重大特性：幂等性和事务。</p></li></ul></li></ul><p><strong>精确一次（Exactly Once） = 幂等性 + 至少一次（ ack=-1 + 分区副本数&gt;=2 + ISR最小副本数量&gt;=2） 。</strong></p><h4 id="生产者事务" tabindex="-1">生产者事务 <a class="header-anchor" href="#生产者事务" aria-label="Permalink to &quot;生产者事务&quot;">​</a></h4><p>开启事务，必须开启幂等性。 开启参数 enable.idempotence 默认为 true，false 关闭。</p><p>Producer 在使用事务功能前，必须先 自定义一个唯一的 transactional.id。有 了 transactional.id，即使客户端挂掉了， 它重启后也能继续处理未完成的事务</p><h4 id="数据有序" tabindex="-1">数据有序 <a class="header-anchor" href="#数据有序" aria-label="Permalink to &quot;数据有序&quot;">​</a></h4><p>1）kafka在1.x版本之前保证数据单分区有序，条件如下：</p><ul><li>max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。</li></ul><p>2）kafka在1.x及以后版本保证数据单分区有序，条件如下：</p><p>（1）未开启幂等性 max.in.flight.requests.per.connection需要设置为1。</p><p>（2）开启幂等性 max.in.flight.requests.per.connection需要设置小于等于5。</p><p>原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据， 故无论如何，都可以保证最近5个request的数据都是有序的。</p><p>如果开启了幂等性且缓存的 请求个数小于5个。会在服 务端重新排序</p><ul><li>retries 当消息发送出现错误的时候，系统会重发消息。retries 表示重试次数。默认是 int 最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1 否则在重试此失败消息的时候，其他的消息可能发送 成功了。</li></ul><h4 id="数据积压-消费者如何提高吞吐量" tabindex="-1">数据积压（消费者如何提高吞吐量） <a class="header-anchor" href="#数据积压-消费者如何提高吞吐量" aria-label="Permalink to &quot;数据积压（消费者如何提高吞吐量）&quot;">​</a></h4><p>1）如果是Kafka消费能力不足，则可以考虑增 加Topic的分区数，并且同时提升消费组的消费者 数量，消费者数 = 分区数。（两者缺一不可）</p><p>2）如果是下游的数据处理不及时：提高每批次拉取的数 量。批次拉取数据过少（拉取数据/处理时间 &lt; 生产速度）， 使处理的数据小于生产的数据，也会造成数据积压。</p><h3 id="leader-和-follower-故障处理细节" tabindex="-1">Leader 和 Follower 故障处理细节 <a class="header-anchor" href="#leader-和-follower-故障处理细节" aria-label="Permalink to &quot;Leader 和 Follower 故障处理细节&quot;">​</a></h3><p>LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset + 1。</p><p>HW（High Watermark）：所有副本中最小的LEO 。</p><h4 id="_1-follower故障" tabindex="-1">1）Follower故障 <a class="header-anchor" href="#_1-follower故障" aria-label="Permalink to &quot;1）Follower故障&quot;">​</a></h4><p>（1） Follower发生故障后会被临时踢出ISR</p><p>（2） 这个期间Leader和Follower继续接收数据</p><p>（3）待该Follower恢复后，Follower会读取本地磁盘记录的 上次的HW，并将log文件高于HW的部分截取掉，从HW开始 向Leader进行同步。</p><p>（4）等该Follower的LEO大于等于该Partition的HW，即 Follower追上Leader之后，就可以重新加入ISR了。</p><h4 id="_1-leader故障" tabindex="-1">1）Leader故障 <a class="header-anchor" href="#_1-leader故障" aria-label="Permalink to &quot;1）Leader故障&quot;">​</a></h4><p>（1） Leader发生故障之后，会从ISR中选出一个新的Leader</p><p>（2）为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据。</p><p><strong>注意：这只能保证副本之间的数据一致性，并不能保 证数据不丢失或者不重复。</strong></p><h3 id="漏消费和重复消费" tabindex="-1">漏消费和重复消费 <a class="header-anchor" href="#漏消费和重复消费" aria-label="Permalink to &quot;漏消费和重复消费&quot;">​</a></h3><h4 id="场景1-重复消费。" tabindex="-1">场景1：重复消费。 <a class="header-anchor" href="#场景1-重复消费。" aria-label="Permalink to &quot;场景1：重复消费。&quot;">​</a></h4><p>自动提交offset引起</p><p>1） Consumer 每5s提交offset</p><p>2）如果提交offset后的2s，consumer挂了</p><p>3）再次重启consumer，则从上一次提交的 offset处继续消费，导致重复消费</p><h4 id="场景1-漏消费" tabindex="-1">场景1：漏消费 <a class="header-anchor" href="#场景1-漏消费" aria-label="Permalink to &quot;场景1：漏消费&quot;">​</a></h4><p>设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线 程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</p><p><strong>思考：怎么能做到既不漏消费也不重复消费呢？详看消费者事务。</strong></p><p>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset 过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质（比 如 MySQL）。</p><h3 id="kafka-eagle-监控" tabindex="-1">Kafka-Eagle 监控 <a class="header-anchor" href="#kafka-eagle-监控" aria-label="Permalink to &quot;Kafka-Eagle 监控&quot;">​</a></h3><h1 id="windows启动" tabindex="-1">windows启动 <a class="header-anchor" href="#windows启动" aria-label="Permalink to &quot;windows启动&quot;">​</a></h1><h6 id="启动zookpeer时出现-不是正确的命令" tabindex="-1">启动zookpeer时出现，不是正确的命令 <a class="header-anchor" href="#启动zookpeer时出现-不是正确的命令" aria-label="Permalink to &quot;启动zookpeer时出现，不是正确的命令&quot;">​</a></h6><p>因为层级太深，文件夹命名太长，改短即可。</p>',71)]))}const f=e(o,[["render",t]]);export{u as __pageData,f as default};
